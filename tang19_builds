#!/usr/bin/python3

import argparse
import json
import os
import pickle
import sys

from batchedGPR import BatchedGaussianProcessRegressor
from graphshift_lib import make_df, make_maskshifts, rmse
import numpy as np
import pandas as pd

parser = argparse.ArgumentParser(description=''.join(('Test data set size and ',
	'alpha effects on Tang19 prediction performance')))
parser.add_argument('--data', '-d', required=False, type=str,
	metavar='<str>', help='xz zipped json database')
parser.add_argument('--atom', '-a', required=False, default='C',
	metavar='<str>', help='atom type to predict on, default is carbon')
parser.add_argument('--trainum', '-n', required=False,
	metavar='<int>', help='training set size')
parser.add_argument('--batchsize', '-b', required=False,
	metavar='<int>', help='batch size')
parser.add_argument('--alpha', '-p', required=False, default=1e-8,
	metavar='<float>', help='alpha level')
parser.add_argument('--shuffle', '-u', required=False,
	action='store_true', help='shuffle or not shuffle dataset')
parser.add_argument('--optimize', '-m', required=False,
	action='store_true', help='optimize or build?')
parser.add_argument('--name', '-f', required=False, default='model.pickle',
	metavar='<str>', help='Name for pickle output file')
parser.add_argument('--save', '-o', required=False,
	metavar='<str>', help='directory for saved models')
parser.add_argument('--config', '-c', required=False,
	metavar='<str>', help='json configuration file')

arg = parser.parse_args()

if arg.config:
	assert(arg.data is None)
	
	with open(arg.config, 'r') as fp:
		config = json.load(fp)
	
	data        = str(config['data'])
	atom        = str(config['atom'])
	n           = int(config['trainum'])
	tol         = float(config['tol'])
	alpha       = float(config['alpha'])
	nv          = int(config['val'])
	batch_size  = int(config['batchsize'])
	out_path    = str(config['save'])
	out_name    = str(config['name'])
	optimize    = bool(config['optimize'])
	shuffle     = bool(config['shuffle'])
	
	h_elm               = float(config['h_elm'])
	h_elm_range         = [float(b) for b in config['h_elm_range']]
	assert(h_elm_range[0] < h_elm_range[1])
	assert(len(h_elm_range) == 2)
	l_scale             = float(config['l_scale'])
	l_scale_range       = [float(b) for b in config['l_scale_range']]
	assert(l_scale_range[0] < l_scale_range[1])
	assert(len(l_scale_range) == 2)
	starting_prob       = float(config['starting_prob'])
	starting_range      = [float(b) for b in config['starting_range']]
	assert(starting_range[0] < starting_range[1])
	assert(len(starting_range) == 2)
	stopping_prob       = float(config['stopping_prob'])
	stopping_range      = [float(b) for b in config['stopping_range']]
	assert(stopping_range[0] < stopping_range[1])
	assert(len(stopping_range) == 2)

if arg.data:
	assert(arg.config is None)
	data       = arg.data
	atom       = str(arg.atom)
	n          = int(arg.trainum)
	tol        = float(arg.tol)
	alpha      = float(arg.alpha)
	nv         = int(arg.val)
	batch_size = int(arg.batchsize)
	out_path   = str(arg.save)
	out_name   = str(arg.name)	

df = pd.read_pickle(data,compression='xz')

os.remove(arg.config)

if shuffle:
	df = df.sample(frac=1.0)

X = df.graphs[:n]
Y  = make_maskshifts(df.shifts[:n].to_list(), df.symbols[:n].to_list(), atom)

if nv == -1:
	Xv = df.graphs[n:]
	Yv = make_maskshifts(df.shifts[n:].to_list(), df.symbols[n:].to_list(), atom)
else:
	Xv = df.graphs[n:n+nv]
	Yv = make_maskshifts(df.shifts[n:n+nv].to_list(), df.symbols[n:n+nv].to_list(), atom)	

train_nodes = [len(g.nodes['!i']) for g in X]
train_nodes = np.sum(np.array(train_nodes))
test_nodes  = [len(g.nodes['!i']) for g in Xv]
test_nodes  = np.sum(np.array(test_nodes))

print(f"""
train graphs: {n}
validation graphs: {nv}
train shifts: {Y.compressed().shape[0]}
train nodes: {train_nodes}
validation shifts: {Yv.compressed().shape[0]}
validation nodes: {test_nodes}
""")

bgpr = BatchedGaussianProcessRegressor(chunk_size=batch_size, alpha=alpha, optimize=optimize)
complete = bgpr.fit(X,Y,tol=tol,x0=[h_elm,l_scale,stopping_prob,starting_prob])
	
if complete:
	train_preds = bgpr.predict(X, Y)
	test_preds  = bgpr.predict(Xv, Yv)
	
	inRMSE  = rmse(train_preds, Y.compressed())
	outRMSE = rmse(test_preds, Yv.compressed())
	
	inMAE  = np.mean(np.abs(train_preds - Y.compressed()))
	outMAE = np.mean(np.abs(test_preds - Yv.compressed()))
	
	print(f'Train RMSE: {inRMSE:1.4E}')
	print(f'Test RMSE : {outRMSE:1.4E}')
	
	print(f'Train MAE: {inMAE:1.4E}')
	print(f'Test MAE: {outMAE:1.4E}')	
	
	bgpr.save(out_path, filename=out_name, overwrite=True)
	
	predictions = {'train':dict(), 'test':dict()}
	predictions['train']['pred'] = train_preds
	predictions['train']['gt']   = Y.compressed()
	predictions['test']['pred'] = test_preds
	predictions['test']['gt']   = Yv.compressed()
	
	pred_file = os.path.join(out_path, 'predictions_'+out_name)
	pickle.dump(predictions, open(pred_file, 'wb'), protocol=3)
else:
	sys.exit('Something wrong')